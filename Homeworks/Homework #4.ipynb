{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "homework-4-starter.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BountyHunter1999/Machine-Learning-Zoom-Camp/blob/main/Homeworks/Homework%20%234.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8I496FyST8l"
      },
      "source": [
        "## Homework 4\n",
        "\n",
        "Use this notebook as a starter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53FDzMRqST8y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEgdpaIiST83"
      },
      "source": [
        "Data:\n",
        "\n",
        "- https://github.com/gastonstat/CreditScoring\n",
        "- Also available [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sQxgHYSZST85",
        "outputId": "403280e1-2fda-4be3-ff17-2f8856d5b995"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-09-27 12:30:24--  https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182489 (178K) [text/plain]\n",
            "Saving to: ‘CreditScoring.csv’\n",
            "\n",
            "CreditScoring.csv   100%[===================>] 178,21K  --.-KB/s    in 0,07s   \n",
            "\n",
            "2021-09-27 12:30:25 (2,47 MB/s) - ‘CreditScoring.csv’ saved [182489/182489]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe4n9h0NST88"
      },
      "source": [
        "## Preparation \n",
        "\n",
        "We'll talk about this dataset in more details in week 6. But for now, use the following code to get started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ca0tKzoST89"
      },
      "source": [
        "df = pd.read_csv('CreditScoring.csv')\n",
        "df.columns = df.columns.str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ozNM1cST9D"
      },
      "source": [
        "Some of the features are encoded as numbers. Use the following code to de-code them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQIrlksST9E"
      },
      "source": [
        "status_values = {\n",
        "    1: 'ok',\n",
        "    2: 'default',\n",
        "    0: 'unk'\n",
        "}\n",
        "\n",
        "df.status = df.status.map(status_values)\n",
        "\n",
        "\n",
        "home_values = {\n",
        "    1: 'rent',\n",
        "    2: 'owner',\n",
        "    3: 'private',\n",
        "    4: 'ignore',\n",
        "    5: 'parents',\n",
        "    6: 'other',\n",
        "    0: 'unk'\n",
        "}\n",
        "\n",
        "df.home = df.home.map(home_values)\n",
        "\n",
        "marital_values = {\n",
        "    1: 'single',\n",
        "    2: 'married',\n",
        "    3: 'widow',\n",
        "    4: 'separated',\n",
        "    5: 'divorced',\n",
        "    0: 'unk'\n",
        "}\n",
        "\n",
        "df.marital = df.marital.map(marital_values)\n",
        "\n",
        "records_values = {\n",
        "    1: 'no',\n",
        "    2: 'yes',\n",
        "    0: 'unk'\n",
        "}\n",
        "\n",
        "df.records = df.records.map(records_values)\n",
        "\n",
        "job_values = {\n",
        "    1: 'fixed',\n",
        "    2: 'partime',\n",
        "    3: 'freelance',\n",
        "    4: 'others',\n",
        "    0: 'unk'\n",
        "}\n",
        "\n",
        "df.job = df.job.map(job_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhSMVvjjST9G"
      },
      "source": [
        "Prepare the numerical variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_hlxnsQST9I"
      },
      "source": [
        "for c in ['income', 'assets', 'debt']:\n",
        "    df[c] = df[c].replace(to_replace=99999999, value=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZsYPvrWST9J"
      },
      "source": [
        "Remove clients with unknown default status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk4LNcBDST9L"
      },
      "source": [
        "df = df[df.status != 'unk'].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOhxfv9rST9L"
      },
      "source": [
        "Create the target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks0DfrYoST9M"
      },
      "source": [
        "df['default'] = (df.status == 'default').astype(int)\n",
        "del df['status']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hAd8kivST9N"
      },
      "source": [
        "## Your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbdXaLjnST9N"
      },
      "source": [
        "What are the categorical variables? What are the numerical?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg3jfyFiST9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40MsWWLxST9P"
      },
      "source": [
        "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-75O93JHST9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "megj1G_PST9R"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
        "\n",
        "Let's do that\n",
        "\n",
        "* For each numerical variable, use it as score and compute AUC with the default variable\n",
        "* Use the training dataset for that\n",
        "\n",
        "\n",
        "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
        "\n",
        "(e.g. `-df_train['expenses']`)\n",
        "\n",
        "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZkU1YUUST9T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j6f21OkST9U"
      },
      "source": [
        "Which numerical variable (among the following 4) has the highest AUC?\n",
        "\n",
        "- seniority\n",
        "- time\n",
        "- income\n",
        "- debt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbT4ZA75ST9V"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "From now on, use these columns only:\n",
        "\n",
        "```\n",
        "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
        "```\n",
        "\n",
        "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
        "\n",
        "```\n",
        "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z488_TphST9W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReziorxVST9X"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
        "\n",
        "- 0.512\n",
        "- 0.612\n",
        "- 0.712\n",
        "- 0.812"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLdrNI7eST9Y"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Now let's compute precision and recall for our model.\n",
        "\n",
        "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
        "* For each threshold, compute precision and recall\n",
        "* Plot them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf_xncvRST9Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqna5u5ST9Z"
      },
      "source": [
        "At which threshold precision and recall curves intersect?\n",
        "\n",
        "* 0.2\n",
        "* 0.4\n",
        "* 0.6\n",
        "* 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yuSZUwrST9a"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
        "\n",
        "This is the formula for computing F1:\n",
        "\n",
        "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
        "\n",
        "Where $P$ is precision and $R$ is recall.\n",
        "\n",
        "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A_IENoZST9b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ytKRlfST9c"
      },
      "source": [
        "At which threshold F1 is maximal?\n",
        "\n",
        "- 0.1\n",
        "- 0.3\n",
        "- 0.5\n",
        "- 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYo9wkk-ST9c"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "\n",
        "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
        "\n",
        "```\n",
        "KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "```\n",
        "\n",
        "* Iterate over different folds of `df_full_train`\n",
        "* Split the data into train and validation\n",
        "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
        "* Use AUC to evaluate the model on validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZZ8QC3LST9d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQBEAbZST9e"
      },
      "source": [
        "How large is standard devidation of the scores across different folds?\n",
        "\n",
        "- 0.001\n",
        "- 0.014\n",
        "- 0.09\n",
        "- 0.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g9WPrsBST9f"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "Now let's use 5-Fold cross-validation to find the best parameter C\n",
        "\n",
        "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
        "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
        "* Compute the mean score as well as the std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJW9hsyfST9f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcKW8FHnST9g"
      },
      "source": [
        "Which C leads to the best mean score?\n",
        "\n",
        "- 0.01\n",
        "- 0.1\n",
        "- 1\n",
        "- 10\n",
        "\n",
        "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoCTfMsVST9g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnnITncHST9h"
      },
      "source": [
        "## Submit the results\n",
        "\n",
        "Submit your results here: https://forms.gle/e497sR5iB36mM9Cs5\n",
        "\n",
        "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
        "\n",
        "## Deadline\n",
        "\n",
        "The deadline for submitting is 04 October 2021, 17:00 CET. After that, the form will be closed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQfiCOz4ST9h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}